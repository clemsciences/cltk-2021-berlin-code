{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073f9622",
   "metadata": {},
   "source": [
    "# About the discovery of America by Vikings with CLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2b96d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The aims of the presentation are to show:\n",
    "- to show how to practically use CLTK,\n",
    "- to understand how CLTK works,\n",
    "- to explore classical texts with CLTK on an exploratory perspective.\n",
    "\n",
    "We analyse here two texts *The saga of Erik the Red* (Eir√≠ks saga rau√∞a, or **ESR**) and *The saga of the Greenlanders* (Gr≈ìnlendinga saga or **GS**) in the original language, namely Old Norse. The sagas tells how Norwegians/Icelanders colonized Greenland and found new lands in what is now America.\n",
    "\n",
    "\n",
    "### Context\n",
    "\n",
    "#### Archeology\n",
    "The discovery of America by Norse people is now a fact. Archeological evidences show the presence of Vikings at *L‚ÄôAnse aux Meadows* in the current Canada. ([The Norse in Newfoundland](https://www.erudit.org/en/journals/nflds/2003-v19-n1-nflds_19_1/nflds19_1art02/) and [A Nature article: Evidence for European presence in the Americas in ad 1021](https://doi.org/10.1038/s41586-021-03972-8).\n",
    "\n",
    "#### Interpretations\n",
    "Scholars interpret **ESR** as a more logical story reinterpreted by the author whereas **GS** is supposedly more raw transcription of an oral tradition. There is a debate on which one came first.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cb21d",
   "metadata": {},
   "source": [
    "## Installing CLTK "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe44782",
   "metadata": {},
   "source": [
    "It works on Posix system: **Linux**, **MacOs**, **Windows** with **WSL** (Windows subsystem for Linux)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb5904",
   "metadata": {},
   "source": [
    "It is a good practice to code in a Python virtual environment. Create a virtual environment to work on a project.\n",
    "\n",
    "```bash\n",
    "$ python3 -m venv cltk_venv\n",
    "$ source cltk_venv/bin/activate\n",
    "(cltk_venv) $ pip install cltk \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3235b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfad9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cltk 1.0.21\n"
     ]
    }
   ],
   "source": [
    "print(cltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86657ff5",
   "metadata": {},
   "source": [
    "## Text retrieval\n",
    "First, we need to retrieve the texts we want to analyse.\n",
    "\n",
    "The texts come from [heimskringla.no](http://heimskringla.no/wiki/Forside)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de324dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def load_file(filename):\n",
    "    with codecs.open(filename, encoding=\"utf-8\") as f:\n",
    "        \n",
    "        return f.read()\n",
    "    \n",
    "def load_clean_text(filename):\n",
    "    text = load_file(filename)\n",
    "    text = text.replace('\"', \"\")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "ESR = load_clean_text(\"eiriks_saga_rauda.txt\")    \n",
    "GS = load_clean_text(\"gr√¶nlendiga_saga.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d619ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. fr√° au√∞i dj√∫p√∫√∞gu ok v√≠fli.\r\n",
      "\r\n",
      "√≥l√°fr h√©t herkonungr, er kalla√∞r var √≥l√°fr hv√≠ti. hann var sonr ingjalds konungs helgasonar, √≥l√°fssonar, gu√∞r√∂√∞arsonar, h√°lfdanarsonar hv√≠tbeins upplendingakonungs.\r\n",
      "√≥l√°fr herja√∞i √≠ vestrv√≠king ok vann dyflinni √° √≠rlandi ok dyflinnarsk√≠ri. √æar ger√∞ist hann konungr yfir. hann fekk au√∞ar dj√∫p√∫√∞gu, d√≥ttur ketils flatnefs, bjarnarsonar bunu, √°g√¶ts manns √≥r n√≥regi. √æorsteinn rau√∞r h√©t sonr √æeira.\r\n",
      "√≥l√°fr fell √° √≠rlandi √≠ orrostu, en au√∞r ok √æorsteinn f√≥ru √æ√° √≠ su√∞reyj\n",
      "\n",
      "===================\n",
      "\n",
      "1. fundit ok byggt gr√¶nland.\r\n",
      "\r\n",
      "√æorvaldr h√©t ma√∞r, sonr √°svalds √∫lfssonar, √∂xna √æ√≥rissonar. √æorvaldr ok eir√≠kr inn rau√∞i, sonr hans, f√≥ru af ja√∞ri til √≠slands fyrir v√≠ga sakir. √æ√° var v√≠√∞a byggt √≠sland. √æeir bjuggu fyrst at dr√∂ngum √° hornstr√∂ndum. √æar anda√∞ist √æorvaldr.\r\n",
      "eir√≠kr fekk √æ√° √æj√≥√∞hildar, d√≥ttur j√∂rundar √∫lfssonar ok √æorbjargar knarrarbringu, er √æ√° √°tti √æorbj√∂rn inn haukd√¶lski. r√©√∞st eir√≠kr √æ√° nor√∞an ok bj√≥ √° eir√≠ksst√∂√∞um hj√° vatnshorni. sonr eir√≠ks ok √æj√≥√∞hildar h√©t leifr.\r\n",
      "enn eftir v\n"
     ]
    }
   ],
   "source": [
    "print(f\"{ESR[:500]}\\n\\n===================\\n\\n{GS[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74029fb6",
   "metadata": {},
   "source": [
    "## CLTK pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494987e",
   "metadata": {},
   "source": [
    "![CLTK pipeline](cltk-Page-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af770b7",
   "metadata": {},
   "source": [
    "If everything is available in CLTK, you only need to import `NLP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce0d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk import NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20fdf1",
   "metadata": {},
   "source": [
    "Default pipeline for Old Norse language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e119d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.0.21'.\n",
      "Pipeline for language 'Old Norse' (ISO: 'non'): `OldNorseTokenizationProcess`, `StopsProcess`, `OldNorseLexiconProcess`.\n"
     ]
    }
   ],
   "source": [
    "non_nlp_default = NLP(\"non\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nlp_default = NLP(\"non\", suppress_banner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ca464",
   "metadata": {},
   "source": [
    "Which processes are there? The answer is in the banner or in an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194a436f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cltk.tokenizers.processes.OldNorseTokenizationProcess,\n",
       " cltk.stops.processes.StopsProcess,\n",
       " cltk.lexicon.processes.OldNorseLexiconProcess]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nlp_default.pipeline.processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80368360",
   "metadata": {},
   "source": [
    "A tokenization process for Old Norse, a stop process (a way to filter uninformative words) and a lexicon process. For our task, we do not need the lexicon process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9071ba",
   "metadata": {},
   "source": [
    "### Custom pipeline for Old Norse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69760a49",
   "metadata": {},
   "source": [
    "To customize our pipeline, we have to import processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bbf5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.tokenizers.processes import OldNorseTokenizationProcess\n",
    "from cltk.stops.processes import StopsProcess\n",
    "from cltk.text.processes import OldNorsePunctuationRemovalProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12118e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.core.data_types import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b089af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pipeline_custom_1 = Pipeline(language=\"non\", description=\"\", processes=[OldNorseTokenizationProcess, StopsProcess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1019952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.0.21'.\n",
      "Pipeline for language 'Old Norse' (ISO: 'non'): `OldNorseTokenizationProcess`, `StopsProcess`.\n"
     ]
    }
   ],
   "source": [
    "non_nlp_custom_1 = NLP(\"non\", custom_pipeline=non_pipeline_custom_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b98f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESR_analysed_1 = non_nlp_custom_1.analyze(ESR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a0e4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 . fr√° au√∞i dj√∫p√∫√∞gu ok v√≠fli . √≥l√°fr h√©t herkonungr , er kalla√∞r var √≥l√°fr hv√≠ti . hann var sonr i'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESR_analysed_1.sentences_strings[0][:100] # it does not work yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5763646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ESR_analysed_1.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74689a44",
   "metadata": {},
   "source": [
    "Hmmm, 1 sentence means that sentences were not recognized.\n",
    "\n",
    "When available processed are not enough, you can create one by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb1a0c",
   "metadata": {},
   "source": [
    "###  Creating a `Process` for CLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17d260",
   "metadata": {},
   "source": [
    "A process is a class that inherits from `Process` and that implements the `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72b19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from cltk.core import CLTKException\n",
    "from cltk.core.data_types import Doc, Process\n",
    "from cltk.sentence.sentence import RegexSentenceTokenizer\n",
    "\n",
    "non_sent_end_chars = [\".\", \"!\", \"?\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OldNorseSentenceTokenizationProcess(Process):\n",
    "\n",
    "    model: object = None\n",
    "\n",
    "    def run(self, input_doc: Doc) -> Doc:\n",
    "        output_doc = deepcopy(input_doc)\n",
    "        sentence_tokenizer = RegexSentenceTokenizer(language=\"non\", sent_end_chars=non_sent_end_chars)\n",
    "\n",
    "        sentences = sentence_tokenizer.tokenize(output_doc.raw, self.model)\n",
    "        sentence_indices = []\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i >= 1:\n",
    "                sentence_indices.append(sentence_indices[-1] + len(sentences[i]))\n",
    "            else:\n",
    "                sentence_indices.append(len(sentence))\n",
    "        sentence_index = 0\n",
    "        for j, word in enumerate(output_doc.words):\n",
    "            if sentence_indices[sentence_index] < word.index_char_stop and\\\n",
    "                    sentence_index + 1 < len(sentence_indices):\n",
    "                sentence_index += 1\n",
    "            word.index_sentence = sentence_index\n",
    "        return output_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25973d",
   "metadata": {},
   "source": [
    "In order to be more language-agnostic, we should add the `algorithm` method, then seperate the `run` method, that can stay in the mother class, from the `algorithm` method that is specific to each language and that is in a daughter class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b6743",
   "metadata": {},
   "source": [
    "The sentence tokenizer, that can be used alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1dc5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.sentence.sentence import RegexSentenceTokenizer\n",
    "\n",
    "sent_end_chars = [\".\", \"!\", \"?\"]\n",
    "\n",
    "\n",
    "class OldNorseRegexSentenceTokenizer(RegexSentenceTokenizer):\n",
    "    \"\"\"``RegexSentenceTokenizer`` for Old Norse.\"\"\"\n",
    "\n",
    "    def __init__(self: object):\n",
    "        super().__init__(language=\"non\", sent_end_chars=sent_end_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad1b9e",
   "metadata": {},
   "source": [
    "The global sentence tokenization process and the Old Norse one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c9e977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from boltons.cacheutils import cachedproperty\n",
    "\n",
    "from cltk.core import CLTKException\n",
    "from cltk.core.data_types import Doc, Process\n",
    "from cltk.sentence.sentence import SentenceTokenizer\n",
    "\n",
    "@dataclass\n",
    "class SentenceTokenizationProcess(Process):\n",
    "\n",
    "    model: object = None\n",
    "\n",
    "    @cachedproperty\n",
    "    def algorithm(self):\n",
    "        raise CLTKException(f\"No sentence tokenization algorithm for language '{self.language}'.\")\n",
    "\n",
    "    def run(self, input_doc: Doc) -> Doc:\n",
    "        output_doc = deepcopy(input_doc)\n",
    "        sentence_tokenizer = self.algorithm\n",
    "        if not isinstance(sentence_tokenizer, SentenceTokenizer):\n",
    "            raise CLTKException(\"Algorithm must be an instance of SentenceTokenizer subclass\")\n",
    "\n",
    "        sentences = sentence_tokenizer.tokenize(output_doc.raw, self.model)\n",
    "        sentence_indices = []\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i >= 1:\n",
    "                sentence_indices.append(sentence_indices[-1] + len(sentences[i]))\n",
    "            else:\n",
    "                sentence_indices.append(len(sentence))\n",
    "        sentence_index = 0\n",
    "        for j, word in enumerate(output_doc.words):\n",
    "            if sentence_indices[sentence_index] < word.index_char_stop and\\\n",
    "                    sentence_index + 1 < len(sentence_indices):\n",
    "                sentence_index += 1\n",
    "            word.index_sentence = sentence_index\n",
    "        return output_doc\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OldNorseSentenceTokenizationProcess(SentenceTokenizationProcess):\n",
    "\n",
    "    @cachedproperty\n",
    "    def algorithm(self):\n",
    "        return OldNorseRegexSentenceTokenizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335b1e1",
   "metadata": {},
   "source": [
    "We can now use it in our custom pipeline at the second position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e83075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pipeline_2 = Pipeline(language=\"non\", description=\"\", \n",
    "                          processes=[OldNorseTokenizationProcess, \n",
    "                                     OldNorseSentenceTokenizationProcess,\n",
    "                                     OldNorsePunctuationRemovalProcess,\n",
    "                                     StopsProcess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40790ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.0.21'.\n",
      "Pipeline for language 'Old Norse' (ISO: 'non'): `OldNorseTokenizationProcess`, `OldNorseSentenceTokenizationProcess`, `OldNorsePunctuationRemovalProcess`, `StopsProcess`.\n"
     ]
    }
   ],
   "source": [
    "non_nlp_2 = NLP(\"non\", custom_pipeline=non_pipeline_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac587e6",
   "metadata": {},
   "source": [
    "Let's analyse our texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c4b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESR_analysed_2 = non_nlp_2.analyze(ESR.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edb56ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_analysed_2 = non_nlp_2.analyze(GS.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26aaeaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 413)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ESR_analysed_2.sentences), len(GS_analysed_2.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc959522",
   "metadata": {},
   "source": [
    "Out texts have the sentences we needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e5174",
   "metadata": {},
   "source": [
    "## Characterisation of the topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce186945",
   "metadata": {},
   "source": [
    "The idea is to find differences in the user vocabulary. A non-factual vocabulary may show assumptions made by the authors. \n",
    "\n",
    "Some words are meaningful to see what it talks about whereas others are just here for syntactic reasons. The least-informative words are named *stop words*. There is a Stop Removal Process for Old Norse. It is however not complete enough. That is why I completed the list of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "404b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_list = [\"hann\", \"√æar\", \"hon\", \"af\", \"ek\", \"sv√°\", \"eigi\", \"n√∫\", \"haf√∞i\", \"honum\", \n",
    "                    \"hafa\", \"henni\", \"√æ√©r\", \"h√∂f√∞u\", \"mun\", \"hans\", \"s√©r\", \"eftir\", \"vera\", \"ekki\", \"m√©r\", \n",
    "                    \"√æ√∫\", \"aftr\", \"hana\", \"sitt\", \"haf\", \"v√©r\", \"s√≠num\", \"hennar\", \"s√≠nu\", \"√æa√∞an\", \n",
    "                    \"allt\", \"sinn\", \"hvat\", \"sama\", \"eitt\", \"einn\", \"ein\", \"√∂llum\", \"√∂√∞rum\", \"\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6815c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_verbs = [\"var\", \"h√©t\", \"v√°ru\", \"f√≥r\", \"kom\", \"t√≥k\", \"fara\", \"m√¶lti\", \"sj√°\", \"kva√∞\", \"√æ√≥tti\", \"f√≥ru\", \n",
    "                \"√°tti\", \"sag√∞i\", \"bj√≥\", \"k√≥mu\", \"kve√∞st\", \"ver√∞a\", \"segir\", \"leita\", \"sigla\", \n",
    "                \"vil\", \"segja\", \"svarar\", \"gekk\", \"koma\", \"hefir\", \"t√≥ku\", \"v√¶ri\", \"vildi\", \"ger√∞ist\", \n",
    "                \"gera\", \"gaf\", \"k√∂llu√∞u\", \"kalla\", \"myndi\", \"mundu\", \"vildu\", \"gengu\", \"eru\", \"skal\", \"√¶tla\",\n",
    "                \"fekk\", \"l√©t\", \"svara√∞i\", \"√æ√≥ttust\", \"farit\", \"s√©\", \"vill\", \"sigldu\", \"vita\", \"taka\", \"mundi\", \n",
    "                \"var√∞\", \"fundu\", \"ger√∞u\", \"ger√∞i\", \"l√°ta\", \"halda\", \"bjuggu\", \"fann\", \"halda\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e05ea8",
   "metadata": {},
   "source": [
    "###  Loading POS annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "018c64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = dict(NC=\"common noun\",\n",
    "     NP=\"proper noun\",\n",
    "     AJ=\"adjective\",\n",
    "     PE=\"personal pronoun\",\n",
    "     PI=\"indefinite pronoun\",\n",
    "     DP=\"possessive determiner\",\n",
    "     DD=\"demonstrative determiner\",\n",
    "     DQ=\"quantifier determiner\",\n",
    "     PD=\"pronoun/determiner\",\n",
    "     NA=\"cardinal determiner\",\n",
    "     NO=\"ordinal determiner\",\n",
    "     VB=\"verb\",\n",
    "     AV=\"adverb\",\n",
    "     AT=\"article\",\n",
    "     AP=\"preposition\",\n",
    "     CC=\"coordinating conjunction\",\n",
    "     CS=\"subordinating conjunction\",\n",
    "     IT=\"interjection\",\n",
    "     IM=\"infinitive marker\",\n",
    "     RP=\"relative particle\",\n",
    "     UA=\"unassigned\"\n",
    "    )\n",
    "\n",
    "informative_pos_tags = [\"NC\", \"NP\", \"AJ\", \"VB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19fe612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"annotated_pos_ESR.csv\", \"r\") as f:\n",
    "    pos_lines_ESR = [line.split(\"\\t\") for line in f.read().split(\"\\n\")]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4af174b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"annotated_pos_GS.csv\", \"r\") as f:\n",
    "    pos_lines_GS = [line.split(\"\\t\") for line in f.read().split(\"\\n\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a566fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = [\".\", \",\", \";\", \"!\", \"?\", \":\", \"\\\"\", \"'\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"--\", \".]\", \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0865869c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'fr√°', 'au√∞i', 'dj√∫p√∫√∞gu', 'ok']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESR_analysed_2.tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03431af",
   "metadata": {},
   "source": [
    "### Aligning tags with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ad4f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_annotations(cltk_doc, spacy_annotations):\n",
    "    \"\"\"\n",
    "    Assign POS tags to words of a CLTK doc from spaCy annotations\n",
    "    \"\"\"\n",
    "    cltk_words = cltk_doc.words\n",
    "    i, j = 0, 0\n",
    "    m = len(cltk_words)\n",
    "    n = len(spacy_annotations)\n",
    "    while i < m and j < n:\n",
    "        spacy_token = spacy_annotations[j][0]\n",
    "        if not spacy_token or spacy_token in PUNCTUATION:\n",
    "            j += 1\n",
    "        elif cltk_words[i].string in PUNCTUATION:\n",
    "            i += 1\n",
    "        else:\n",
    "            #print(spacy_token.lower(), cltk_words[i].string)\n",
    "            if spacy_token.lower() == cltk_words[i].string:\n",
    "                \n",
    "                cltk_words[i].xpos = spacy_annotations[j][1]\n",
    "            else:\n",
    "                cltk_words[i].xpos = \"UA\"\n",
    "            i += 1\n",
    "            j += 1\n",
    "    \n",
    "    cltk_doc.words = cltk_words\n",
    "    return cltk_doc\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e657baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESR_analysed_2 = align_annotations(ESR_analysed_2, pos_lines_ESR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93093c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PE'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESR_analysed_2.words[78].xpos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1baa8",
   "metadata": {},
   "source": [
    "### Filtering words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "787f2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f21e743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kiw(cltk_word, pos_tags=None):\n",
    "    \n",
    "    if pos_tags is None:\n",
    "        pos_tags = informative_pos_tags\n",
    "    return not cltk_word.stop and cltk_word.string and\\\n",
    "        cltk_word.string not in custom_stop_list and\\\n",
    "        cltk_word.string not in common_verbs and\\\n",
    "        cltk_word.xpos in pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e707371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('menn', 40),\n",
       " ('eir√≠kr', 29),\n",
       " ('ma√∞r', 24),\n",
       " ('√æorbj√∂rn', 24),\n",
       " ('karlsefni', 23),\n",
       " ('leifr', 22),\n",
       " ('landit', 17),\n",
       " ('vetr', 16),\n",
       " ('verit', 16),\n",
       " ('skip', 14),\n",
       " ('manna', 14),\n",
       " ('land', 13),\n",
       " ('b√≥ndi', 13),\n",
       " ('sonr', 12),\n",
       " ('kona', 12),\n",
       " ('sumar', 11),\n",
       " ('gu√∞r√≠√∞r', 11),\n",
       " ('ormr', 11),\n",
       " ('bjarni', 11),\n",
       " ('d√≥ttur', 10),\n",
       " ('m√∂nnum', 10),\n",
       " ('gr√¶nlands', 10),\n",
       " ('mikill', 10),\n",
       " ('hafi', 10),\n",
       " ('gr√¶nlandi', 10),\n",
       " ('au√∞r', 9),\n",
       " ('skipi', 9),\n",
       " ('einarr', 9),\n",
       " ('√æorkell', 9),\n",
       " ('vetrinn', 9),\n",
       " ('skr√¶lingar', 9),\n",
       " ('f√∂√∞ur', 8),\n",
       " ('kristni', 7),\n",
       " ('f√©', 7),\n",
       " ('landi', 7),\n",
       " ('eir√≠ksson', 7),\n",
       " ('snorri', 7),\n",
       " ('konungr', 6),\n",
       " ('konu', 6),\n",
       " ('eir√≠ki', 6),\n",
       " ('sumarit', 6),\n",
       " ('√≠slandi', 6),\n",
       " ('d√≥ttir', 6),\n",
       " ('r√°√∞', 6),\n",
       " ('m√°li', 6),\n",
       " ('l√°', 6),\n",
       " ('b√°tinn', 6),\n",
       " ('√≥l√°fr', 5),\n",
       " ('√≠rlandi', 5),\n",
       " ('fell', 5)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(word.string,word.xpos) for word in ESR_analysed_2.words if kiw(word)]\n",
    "c_ESR = Counter([w[0] for w in a])\n",
    "c_ESR.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d96ddb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_analysed_2 = align_annotations(GS_analysed_2, pos_lines_GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10d6ab37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leifr', 33),\n",
       " ('skip', 30),\n",
       " ('land', 25),\n",
       " ('menn', 21),\n",
       " ('landit', 20),\n",
       " ('ma√∞r', 17),\n",
       " ('eir√≠kr', 16),\n",
       " ('skipi', 15),\n",
       " ('gu√∞r√≠√∞r', 15),\n",
       " ('manna', 14),\n",
       " ('√æorvaldr', 13),\n",
       " ('vetr', 13),\n",
       " ('gr√¶nlandi', 13),\n",
       " ('bjarni', 13),\n",
       " ('landi', 12),\n",
       " ('karlsefni', 12),\n",
       " ('mikil', 11),\n",
       " ('ba√∞', 11),\n",
       " ('sonr', 10),\n",
       " ('kona', 10),\n",
       " ('skips', 10),\n",
       " ('stund', 9),\n",
       " ('br√¶√∞r', 9),\n",
       " ('freyd√≠s', 9),\n",
       " ('v√°rit', 8),\n",
       " ('eir√≠ksfjar√∞ar', 8),\n",
       " ('gr√¶nlands', 8),\n",
       " ('fer√∞', 8),\n",
       " ('sk√°la', 8),\n",
       " ('landinu', 7),\n",
       " ('br√°tt', 7),\n",
       " ('li√∞i', 7),\n",
       " ('eir√≠ks', 6),\n",
       " ('sumarit', 6),\n",
       " ('mikill', 6),\n",
       " ('f√∂√∞ur', 6),\n",
       " ('skipit', 6),\n",
       " ('burt', 6),\n",
       " ('gu√∞r√≠√∞i', 6),\n",
       " ('v√≠nlands', 6),\n",
       " ('b√≥ndi', 6),\n",
       " ('v√≠nlandi', 6),\n",
       " ('rau√∞i', 5),\n",
       " ('√≠slands', 5),\n",
       " ('sumar', 5),\n",
       " ('gr√¶nland', 5),\n",
       " ('vetrinn', 5),\n",
       " ('brattahl√≠√∞', 5),\n",
       " ('fj√°r', 5),\n",
       " ('bjarna', 5)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [(word.string,word.xpos) for word in GS_analysed_2.words if kiw(word)]\n",
    "c_GS = Counter([w[0] for w in b])\n",
    "c_GS.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087572be",
   "metadata": {},
   "source": [
    "## Datation of texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa2ed2",
   "metadata": {},
   "source": [
    "One way to estimate the date of writing of a text is by using linguistic features.\n",
    "\n",
    "[https://timarit.is/page/7340957](https://timarit.is/page/7340957)\n",
    "\n",
    "> The of/um particle can be used as a dating criterium only when the material for analysis is extensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bbbb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 58 matches:\n",
      " var b√∫inn fylg√∞u √æeir styrr honum √∫t um eyjar eir√≠kr sag√∞i √æeim at hann √¶tla√∞\n",
      " sonr √∫lfs kr√°ku s√° er hann rak vestr um haf √æ√° er hann fann gunnbjarnarsker k\n",
      " eir√≠ksey n√¶r mi√∞ri inni eystri bygg√∞ um v√°rit eftir f√≥r hann til eir√≠ksfjar√∞a\n",
      "√≠ksey fyrir mynni eir√≠ksfjar√∞ar eftir um sumarit f√≥r hann til √≠slands ok kom s\n",
      " landit h√©ti vel eir√≠kr var √° √≠slandi um vetrinn en um sumarit eftir f√≥r hann \n",
      "el eir√≠kr var √° √≠slandi um vetrinn en um sumarit eftir f√≥r hann at byggja land\n",
      " eyrar er fa√∞ir hans haf√∞i brot siglt um v√°rit √æau t√≠√∞endi √æ√≥ttu bjarna mikil \n",
      " √æetta d√¶gr √°√∞r √æeir s√° land ok r√¶ddu um me√∞ s√©r hvat landi √æetta mun vera en \n",
      "ir√∞ma√∞r jarls ok f√≥r √∫t til gr√¶nlands um sumarit eftir var n√∫ mikil umr√¶√∞a um \n",
      " um sumarit eftir var n√∫ mikil umr√¶√∞a um landaleitan leifr sonr eir√≠ks rau√∞a √≥\n",
      " m√¶lti leifr eigi er oss n√∫ √æat or√∞it um √æetta land sem bjarna at v√©r hafim ei\n",
      "r af landinu ok gengu √æar upp ok s√°st um √≠ g√≥√∞u ve√∞ri ok fundu √æat at d√∂gg var\n",
      "b√∫√∞ir t√≥ku √æat r√°√∞ s√≠√∞an at b√∫ast √æar um √æann vetr ok ger√∞u √æar h√∫s mikil hv√°r\n",
      "haf√∞i √æar eyktar sta√∞ ok dagm√°la sta√∞ um skammdegi en er √æeir h√∂f√∞u lokit h√∫sg\n",
      "ldi ok skilist eigi n√∫ ger√∞u √æeir sv√° um stund leifr ger√∞i √Ωmisst at hann f√≥r \n",
      "str at sj√° vitr ma√∞r ok g√≥√∞r h√≥fsma√∞r um alla hluti 4 leifr inn heppni fann me\n",
      "n√© v√≠nber n√∫ sv√°fu √æeir af √æ√° n√≥tt en um morguninn m√¶lti leifr vi√∞ h√°seta s√≠na\n",
      "t ok eir√≠kr rau√∞i n√∫ var umr√¶√∞a mikil um v√≠nlandsf√∂r leifs ok √æ√≥tti √æorvaldi b\n",
      "itt ok heldu √≠ haf ok er engi fr√°s√∂gn um fer√∞ √æeira fyrr en √æeir koma til v√≠nl\n",
      " v√≠nlands til leifsb√∫√∞a ok bjuggu √æar um skip sitt ok s√°tu um kyrrt √æann vetr \n",
      "√∞a ok bjuggu √æar um skip sitt ok s√°tu um kyrrt √æann vetr ok veiddu fiska til m\n",
      "vetr ok veiddu fiska til matar s√©r en um v√°rit m√¶lti √æorvaldr at √æeir skyldu b\n",
      "fara fyrir vestan landit ok kanna √æar um sumarit √æeim s√Ωndist landit fagrt ok \n",
      "nga s√≠√∞an aftr √° h√∂f√∞ann ok sj√°st √æar um ok sj√° inn √≠ fj√∂r√∞inn h√¶√∞ir n√∂kkurar \n",
      "v√° gera √æeir en skr√¶lingar skutu √° √æ√° um stund en fl√Ωja s√≠√∞an burt sem √°kafast\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "t = Text(GS_analysed_2.tokens)\n",
    "t.concordance(\"um\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dbcdeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fylg√∞u/VB √æeir/DD styrr/AP honum/PE √∫t/AV um/AP eyjar/NC eir√≠kr/NC sag√∞i/VB √æeim/DD\n",
      "s√°/DD er/RP hann/PE rak/VB vestr/AV um/AP haf/NC √æ√°/AV er/RP hann/PE\n",
      "n√¶r/AV mi√∞ri/AJ inni/AV eystri/AJ bygg√∞/NC um/VB v√°rit/NC eftir/VP f√≥r/VB hann/PE\n",
      "eir√≠ksey/NC fyrir/AP mynni/NC eir√≠ksfjar√∞ar/NC eftir/AV um/AP sumarit/NC f√≥r/VB hann/PE til/VP\n",
      "vel/AV eir√≠kr/NC var/VB √°/AP √≠slandi/NC um/AP vetrinn/NC en/CC um/AP sumarit/NC\n",
      "√°/AP √≠slandi/NC um/AP vetrinn/NC en/CC um/AP sumarit/NC eftir/VP f√≥r/VB hann/PE\n",
      "fa√∞ir/NC hans/PE haf√∞i/VB brot/AV siglt/VB um/AP v√°rit/NC √æau/AJ t√≠√∞endi/NC √æ√≥ttu/VB\n",
      "√æeir/DD s√°/VB land/NC ok/CC r√¶ddu/NC um/VP me√∞/AP s√©r/PE hvat/PQ landi/NC\n",
      "ok/CC f√≥r/VB √∫t/AV til/AP gr√¶nlands/NP um/AP sumarit/NC eftir/AP var/NC n√∫/AV\n",
      "eftir/AP var/NC n√∫/AV mikil/AJ umr√¶√∞a/NC um/AP landaleitan/NC leifr/NC sonr/NC eir√≠ks/NC\n",
      "er/VB oss/PE n√∫/AV √æat/DD or√∞it/VB um/AP √æetta/DD land/NC sem/CS bjarna/VB\n",
      "gengu/VB √æar/AV upp/AV ok/CC s√°st/NC um/AP √≠/AP g√≥√∞u/AJ ve√∞ri/NC ok/CC\n",
      "r√°√∞/NC s√≠√∞an/AV at/IM b√∫ast/VB √æar/AV um/AP √æann/DD vetr/NC ok/CC ger√∞u/VB\n",
      "eyktar/AJ sta√∞/NC ok/CU dagm√°la/NC sta√∞/NC um/AP skammdegi/PD en/VB er/CS √æeir/DD\n",
      "eigi/AV n√∫/NC ger√∞u/VB √æeir/DD sv√°/AV um/AP stund/NC leifr/NC ger√∞i/VB √Ωmisst/VB\n",
      "vitr/AJ ma√∞r/NC ok/CU g√≥√∞r/AJ h√≥fsma√∞r/NC um/AP alla/AJ hluti/NC 4/NA leifr/NC\n",
      "√æeir/DD af/AP √æ√°/DD n√≥tt/NC en/CC um/AP morguninn/NC m√¶lti/VB leifr/NC vi√∞/AP\n",
      "rau√∞i/AJ n√∫/NC var/VB umr√¶√∞a/NC mikil/AJ um/AP v√≠nlandsf√∂r/NC leifs/AP ok/CC √æ√≥tti/VB\n",
      "haf/NC ok/CC er/VB engi/PI fr√°s√∂gn/VB um/AP fer√∞/NC √æeira/DD fyrr/AV en/CS\n",
      "til/AP leifsb√∫√∞a/NC ok/CC bjuggu/NC √æar/AV um/AP skip/NC sitt/DP ok/CC s√°tu/VB\n",
      "um/AP skip/NC sitt/DP ok/CC s√°tu/VB um/AP kyrrt/AJ √æann/DD vetr/NC ok/CC\n",
      "fiska/NC til/AP matar/NC s√©r/PE en/VB um/AP v√°rit/NC m√¶lti/VB √æorvaldr/AJ at/CU\n",
      "vestan/AV landit/NC ok/CC kanna/VB √æar/AV um/AP sumarit/NC √æeim/AV s√Ωndist/NC landit/NC\n",
      "√°/AP h√∂f√∞ann/NC ok/CC sj√°st/VB √æar/AV um/AP ok/AV sj√°/VB inn/AV √≠/AP\n",
      "en/CC skr√¶lingar/VB skutu/NC √°/AP √æ√°/DD um/AP stund/NC en/CC fl√Ωja/VB s√≠√∞an/AV\n",
      "ek/PE muni/VB √æar/AV b√∫a/VB √°/VP um/AP stund/NC √æar/NC skulu√∞/VB √æ√©r/PE\n",
      "skipsins/NC n√∫/NC b√∫ast/VB √æeir/DD √æa√∞an/AV um/AP v√°rit/NC eftir/VP til/AP gr√¶nlands/NC\n",
      "vestri/VB bygg√∞/NC √æorsteinn/NC leita√∞i/VB √æeim/DD um/AP vistir/NC ok/CC fekk/VB vistir/NC\n",
      "n√∫/NC kom/VB hann/PE eftir/AP √æeim/DD um/AP morgininn/NC me√∞/AP eyki/NC ok/CC\n",
      "til/AP skips/NC ok/CC b√∫a/VB √æar/AV um/AP √æv√≠/DD at/CS ek/PE vil/VB\n",
      "me√∞/VB undarligum/NC h√¶tti/NC er/VB n√∫/AV um/AP h√∫sfreyju/NC v√°ra/DP √æv√≠/DD at/CS\n",
      "f√¶r√∞i/NC √≠/AP brott/AV ok/CC bj√≥/VB um/AP hann/NC var/VB b√¶√∞i/AV mikill/AJ\n",
      "gegnt/AP l√≠ki/NC √æorsteins/NC ok/CC tal√∞i/VB um/AP fyrir/AP henni/PE marga/AJ vega/NC\n",
      "√æorsteinn/PE aftr/AV ok/CC var/VB b√∫it/VB um/AP l√≠k/NC hans/PE ok/CC f√¶rt/VB\n",
      "hann/PE haf√∞i/VB heitit/VB hann/NC seldi/VB um/AP v√°rit/NC j√∂r√∞/NC s√≠na/DP ok/CC\n",
      "st√≥rau√∞igr/AJ at/AP f√©/NC ok/CC var/VB um/AP vetrinn/NC √≠/AP brattahl√≠√∞/NC me√∞/AP\n",
      "var√∞/VB √∫rigt/NC ok/CC ger√∞i/VB mikit/AJ um/AP sik/PE √æeir/NC h√∂f√∞u/- haft/VB\n",
      "karlsefni/AP l√¶tr/NC gera/VB sk√≠√∞gar√∞/NC rammligan/NC um/AP b√¶/NC sinn/VB ok/CC bjuggust/VB\n",
      "b√¶/NC sinn/VB ok/CC bjuggust/VB √æar/AV um/AP √≠/NC √æann/DD t√≠ma/NC f√¶ddi/NC\n",
      "heldr/AV l√°g/VB ok/CC haf√∞i/VB dregil/VB um/AP h√∂fu√∞/NC ok/CC lj√≥sj√∂rp/VB √°/AP\n",
      "√∂xi/NC eina/NA ok/CC leit/VB √°/VP um/AP stund/NC ok/CC reiddi/VB at/AP\n",
      "vi√∞/AP √∂xinni/NC ok/CC leit/VB √°/VP um/AP stund/NC ok/CC varp/VB henni/PE\n",
      "s√≠nu/DP heilu/AJ ok/CC v√°ru/VB √æar/AV um/AP vetrinn/NC 8/NA √≥d√¶√∞isverk/NC freyd√≠sar/NC\n",
      "n√∫/NC tekst/NC umr√¶√∞a/NC at/IM n√Ωju/AJ um/AP v√≠nlandsfer√∞/AJ √æv√≠/DD at/CS s√∫/DD\n",
      "manna/NC √°/AP skipi/NC ok/CC konur/NC um/AP fram/AV en/VB freyd√≠s/NC br√°/VB\n",
      "√°/AP vatnsstr√∂ndu/NC ok/CC bjuggu/NC vel/AV um/AP en/VB freyd√≠s/NC l√©t/VB fella/VB\n",
      "h√∂f√∞/NC skemmtan/NC sv√°/NC var/VB gert/VB um/AP stund/NC √æar/AV til/AP er/CS\n",
      "at/CU freyd√≠s/NC √æ√≥ttist/UA allvel/AV hafa/VB um/AP r√°√∞it/NC ok/CC m√¶lti/VB vi√∞/AP\n",
      "n√∫/NC bjuggu/NC √æeir/DD skipit/NC snemma/AV um/AP v√°rit/NC √æat/DD er/RP √æeir/DD\n",
      "illsku/NC at/CS eigi/AV k√¶mi/VB upp/AV um/AP s√≠√∞ir/NC n√∫/NC kom/VB √æetta/DD\n",
      "s√≠√∞ir/NC n√∫/NC kom/VB √æetta/DD upp/AV um/AP s√≠√∞ir/NC fyrir/AP leif/NC br√≥√∞ur/NC\n",
      "ok/CC p√≠ndi/VB √æ√°/AV til/AP sagna/NC um/AP √æenna/DD atbur√∞/NC allan/AJ jafnsaman/NC\n",
      "sv√°/AV fram/AV at/CS engum/PI √æ√≥tti/VB um/AP √æau/DD vert/AJ √æa√∞an/AV √≠/AP\n",
      "ok/CC h√∂ldnu/NC ok/CC sat/VB √æar/AV um/AP vetrinn/NC ok/CC seldi/VB varning/NC\n",
      "g√∂fgustum/AJ m√∂nnum/NC √≠/AP n√≥regi/NP en/CC um/AP v√°rit/NC eftir/VP bj√≥/VB hann/PE\n",
      "√æar/AV upp/AV sett/VB skip/NC hans/PE um/AP vetrinn/NC en/VB um/AP v√°rit/NC\n",
      "skip/NC hans/PE um/AP vetrinn/NC en/VB um/AP v√°rit/NC keypti/VB hann/PE glaumb√¶jarland/AV\n",
      "gerst/VB sagt/VB allra/DQ manna/NC atbur√∞i/NC um/AP farar/NC √æessar/DD allar/AJ er/RP\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for k, word in enumerate(GS_analysed_2.words):\n",
    "    \n",
    "    if word.string == \"um\":\n",
    "        if 0 < k - 5 and k + 5 < len(GS_analysed_2.words):\n",
    "            print(\" \".join([f\"{w.string}/{w.xpos}\" for w in GS_analysed_2.words[k-5:k+5]]))\n",
    "                \n",
    "        # print(d[0].string, d[1].string, d[2].string, d[3].string, d[4].string, word.xpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c8852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64376f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f8ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a4c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1390281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e35a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33bf14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
